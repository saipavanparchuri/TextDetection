{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Text Recognition System\n",
    "\n",
    "## Problem Definition\n",
    "\n",
    "Our application aims to facilitate the conversion of handwritten text into digital format. Users can upload images containing handwritten English block letters, including both uppercase and lowercase letters, as well as numeric digits. With a character set of 62 possibilities, spanning from 0-9, A-Z, and a-z, our goal is to accurately transcribe users' handwritten characters into textual characters.\n",
    "\n",
    "This application targets a broad audience, including students, educators, researchers, and office workers. These users frequently engage in handwritten note-taking activities, and our application aims to streamline their workflow by allowing them to easily digitize their handwritten notes. This not only enhances organization but also facilitates the seamless integration of handwritten content into digital platforms.\n",
    "\n",
    "Our application prioritizes simplicity and efficiency. Users expect minimal effort and swift results, thus emphasizing the need for low latency and user-friendly interfaces. \n",
    "\n",
    "## System Design\n",
    "\n",
    "Our system consists of several key components:\n",
    "\n",
    "- **Data Preprocessing:** We preprocess handwritten images, converting them into a suitable format for model training.Data preprocessing involves transforming uploaded images into a format suitable for the machine learning model. This includes resizing, grayscale conversion, and thresholding to enhance image quality.\n",
    "- **Modeling:** We design and train a CNN architecture using PyTorch to perform the handwritten text recognition task. Model is trained on a dataset containing handwritten characters, the model learns to accurately classify images into their corresponding textual characters.\n",
    "- **Deployment:** The trained model can be deployed for inference on new handwritten images. The user interface provides a seamless experience for users to upload images and receive digital text outputs. Minimalistic design and intuitive interactions ensure ease of use for users of all backgrounds.\n",
    "- **User Experience:** We provide a simple interface for users to interact with the system, allowing them to upload images for text recognition.\n",
    "\n",
    "Central design decisions include the choice of implementing CNN model for its effectiveness in image classification tasks and the utilization of PyTorch due to its flexibility and ease of use in implementing neural networks.\n",
    "\n",
    "## Machine Learning Component\n",
    "\n",
    "The CNN model is trained on a custom dataset comprising handwritten characters. We preprocess the images by resizing them, converting to grayscale, and applying thresholding to create binary images. The model architecture consists of multiple convolutional layers followed by fully connected layers. We optimize the model using the Adam optimizer and experiment with varying hyperparameters to improve performance.\n",
    "\n",
    "## System Evaluation\n",
    "\n",
    "We evaluate the system's performance by measuring accuracy on a separate test dataset. Additionally, we analyze training and validation loss to assess model convergence and potential overfitting. Our results demonstrate consistent improvement in accuracy over epochs, indicating the effectiveness of the proposed approach. However, we note that execution time increases with model complexity, highlighting a trade-off between performance and efficiency.\n",
    "\n",
    "## Application Demonstration\n",
    "\n",
    "To demonstrate the application, users can upload images containing handwritten text, and the system will provide the transcribed text. The interface is intuitive and user-friendly, allowing seamless interaction with the text recognition functionality. Detailed instructions on using the application are provided to ensure a smooth user experience.\n",
    "\n",
    "## Reflection\n",
    "\n",
    "Throughout the project, we encountered both successes and challenges. The CNN model proved effective in recognizing handwritten text, demonstrating steady improvement in accuracy. However, optimizing hyperparameters and managing execution time were ongoing challenges. In the future, we plan to explore more advanced architectures and optimization techniques to further enhance performance.\n",
    "\n",
    "## Broader Impacts\n",
    "\n",
    "Our application has potential uses in various domains, including digitization of handwritten documents and aiding individuals with disabilities. However, we recognize the importance of mitigating unintended uses and potential biases in the system. We remain committed to ethical design practices and continual improvement to minimize harm and maximize societal benefit.\n",
    "\n",
    "## References\n",
    "\n",
    "- Streamlit Documentation:https://mafda.medium.com/prototyping-a-ml-app-with-streamlit-fastapi-hugging-face-f21f14e7d239\n",
    "- Convolutional Neural Networks Tutorial:https://github.com/zademn/mnist-mlops-learning\n",
    "- Kaggle Handwritten Datasets: https://www.kaggle.com/code/mohammadkumail/handwritten-character-recognition-deep-learning\n",
    "- ChatGPT 3.5\n",
    "\n",
    "\n",
    "## Model Objectives:\n",
    "* Starting with a simple model, try creating a more advanced CNN model that can be easily tuned\n",
    "* Create models with varying depth (number of convolutional layers) to observe performance vs time consumption\n",
    "* Apply various hyperparameter tuning techniques to CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.transforms import Normalize, ToTensor\n",
    "import torch.nn as nn  # neural network\n",
    "import torch.optim as optim  # optimization layer\n",
    "import torch.nn.functional as F  # activation functions\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import time\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, csv_file, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_df = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.label_mapping = {label: index for index, label in enumerate(\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")}\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.data_dir, self.data_df.iloc[idx, 0])\n",
    "        image = Image.open(img_name)\n",
    "        label_str = self.data_df.iloc[idx, 1]\n",
    "        label = self.label_mapping[label_str]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(label)\n",
    "\n",
    "class ToBinary(object):\n",
    "    \"\"\"\n",
    "    Convert a grayscale image to a binary image using thresholding.\n",
    "\n",
    "    Args:\n",
    "    - threshold: Threshold value for binarization (default: 128)\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold=128):\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Apply the transform to the input image.\n",
    "\n",
    "        Args:\n",
    "        - img: Input grayscale image (PIL Image or tensor)\n",
    "\n",
    "        Returns:\n",
    "        - bin_img: Binary image (PIL Image or tensor)\n",
    "        \"\"\"\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            # Convert tensor to PIL Image\n",
    "            img = transforms.ToPILImage()(img)\n",
    "\n",
    "        # Convert the image to grayscale (if not already)\n",
    "        if img.mode != 'L':\n",
    "            img = img.convert('L')\n",
    "\n",
    "        # Apply thresholding to convert to binary image\n",
    "        bin_img = img.point(lambda p: p > self.threshold and 255)\n",
    "\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            # Convert PIL Image to tensor\n",
    "            bin_img = transforms.ToTensor()(bin_img)\n",
    "\n",
    "        return bin_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
    "        self.fc2 = nn.Linear(128, 62)  # 62 classes for EMNIST ByClass dataset\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize your CNN model\n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 88/88 [00:32<00:00,  2.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 22/22 [00:07<00:00,  2.92batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 88/88 [00:32<00:00,  2.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 22/22 [00:07<00:00,  2.92batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 88/88 [00:32<00:00,  2.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 22/22 [00:07<00:00,  2.92batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 88/88 [00:32<00:00,  2.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 22/22 [00:07<00:00,  2.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 88/88 [00:32<00:00,  2.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 22/22 [00:07<00:00,  2.92batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define your loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define transforms for the dataset\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),    # Resize images to (32, 32)\n",
    "    transforms.Grayscale(), # Convert images to grayscale\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomRotation(20),\n",
    "    ToBinary(threshold=128),        # Convert images to binary using thresholding\n",
    "    transforms.ToTensor()           # Convert images to PyTorch tensors\n",
    "])\n",
    "\n",
    "# Create a custom dataset and dataloader\n",
    "dataset = CustomDataset(data_dir='data/',\n",
    "                        csv_file='data/english.csv',\n",
    "                        transform=data_transform)\n",
    "\n",
    "# Split dataset into train and test partitions\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create dataloaders for train and test partitions\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "model_path = '/Users/smritikumari/Desktop/ML_Project/hand_dataset_model/model.pt'\n",
    "\n",
    "# model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    # Calculate average loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(f\"Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Testing\", unit=\"batch\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Accuracy on test set: {accuracy:.4f}\")\n",
    "torch.save(model.to(torch.device('cpu')).state_dict(), '/Users/smritikumari/Desktop/ML_Project/hand_dataset_model/model_binary.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os \n",
    "\n",
    "# def emnist_byclass_label_to_char(label):\n",
    "#     if label < 10:\n",
    "#         return str(label)  # Digits 0-9\n",
    "#     elif label < 36:\n",
    "#         return chr(label + 55)  # Capital letters A-Z (ASCII 65-90)\n",
    "#     else:\n",
    "#         return chr(label + 61)  # Small letters a-z (ASCII 97-122)\n",
    "\n",
    "def emnist_byclass_label_to_char(label):\n",
    "        # Decode label using the label mapping\n",
    "    label_mapping = {label: index for index, label in enumerate(\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")}\n",
    "    return list(label_mapping.keys())[list(label_mapping.values()).index(label)]\n",
    "\n",
    "def infer(net, test_folder):\n",
    "    '''\n",
    "    Returns test accuracy\n",
    "    \n",
    "        Parameters:\n",
    "            net (CNN): a trained model\n",
    "            args (ArgumentParser): hyperparameters\n",
    "        \n",
    "        Returns:\n",
    "            test_acc (float): test accuracy of a trained model\n",
    "    '''\n",
    "\n",
    "    # net = CNN()\n",
    "    \n",
    "    # net.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    net.eval()\n",
    "\n",
    "    def predict_image(image_path, model):\n",
    "        image = Image.open(image_path)  # Convert to grayscale\n",
    "        # Define transforms for the dataset\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((32, 32)),    # Resize images to (32, 32)\n",
    "            transforms.Grayscale(),         # Convert images to grayscale\n",
    "            ToBinary(threshold=128),        # Convert images to binary using thresholding\n",
    "            transforms.ToTensor()           # Convert images to PyTorch tensors\n",
    "        ])\n",
    "        image = transform(image)\n",
    "        image = torch.unsqueeze(image, 0)  # Add batch dimension\n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            return predicted.item()\n",
    "\n",
    "\n",
    "    # Iterate through each image in the folder\n",
    "    for filename in os.listdir(test_folder):\n",
    "        if filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(test_folder, filename)\n",
    "            predicted_label = predict_image(image_path, net)\n",
    "            predicted_char = emnist_byclass_label_to_char(predicted_label)\n",
    "            print(f\"you wrote: for {filename}: {predicted_char}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you wrote: for h.png: h\n",
      "you wrote: for i.png: i\n",
      "you wrote: for Z.png: Z\n",
      "you wrote: for AA.png: h\n",
      "you wrote: for O.png: O\n",
      "you wrote: for test A.png: R\n",
      "you wrote: for PP.png: H\n",
      "you wrote: for B.png: f\n",
      "you wrote: for C.png: C\n",
      "you wrote: for BB.png: K\n",
      "you wrote: for 5.png: 5\n",
      "you wrote: for A.png: A\n",
      "you wrote: for w.png: d\n",
      "you wrote: for 6.png: E\n",
      "you wrote: for D.png: B\n",
      "you wrote: for 2.png: 2\n",
      "you wrote: for s.png: E\n",
      "you wrote: for e.png: R\n",
      "you wrote: for g.png: 5\n",
      "you wrote: for P.png: F\n",
      "you wrote: for CC.png: G\n",
      "you wrote: for Q.png: d\n",
      "you wrote: for f.png: f\n"
     ]
    }
   ],
   "source": [
    "#Test inference code\n",
    "model_path = '/Users/smritikumari/Desktop/ML_Project/hand_dataset_model/model.pt'\n",
    "test_folder = '/Users/smritikumari/Desktop/ML_Project/hand_dataset_model/test_imgs/'\n",
    "infer(model, test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized Text: C0ZN\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAAEFCAYAAACLnfoLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABg70lEQVR4nO3dd3yN9/s/8Nd9Vk72XsQWm9hEFRWqS5WiaK0qNYu2lFKqGlWtmlWz1reKolR1ULNmjSqJHcSWvcfJOef+/eGT/KjR5L7vk3Of5PV8PPJoce7rXCHnnPt6j+stiKIogoiIiIiISGEaeydAREREREQlE4sNIiIiIiKyCRYbRERERERkEyw2iIiIiIjIJlhsEBERERGRTbDYICIiIiIim2CxQURERERENsFig4iIiIiIbILFBhERERER2QSLDSIioiISBAHDhw+3dxpERKrHYoOIiOh/YmJi8Pbbb6Ny5cowGo3w8PDAU089hTlz5iA7O9ve6cl269YtfPzxxzh58mSxPucbb7yB6tWrw93dHV5eXmjatClWrlwJURSLLQ8isg+dvRMgIiJSg23btqFbt25wcnJCnz59UKdOHZhMJuzfvx9jxoxBdHQ0Fi9ebO80Zbl16xamTJmCihUron79+sXynAkJCbhx4wa6du2K8uXLIy8vDzt27EC/fv1w/vx5TJs2rVjyICL7YLFBRESl3pUrV9CjRw9UqFABu3btQnBwcMGfDRs2DJcuXcK2bduKNafMzEy4uroW63NK9aRc69Wrhz179jzwe8OHD0fHjh0xd+5cTJ06FVqtthiyJCJ74DIqInoA16JTaTRjxgxkZGRg2bJlDxQa+apWrYqRI0c+9PubN29GnTp14OTkhNq1a+O333574M9jY2MxdOhQVK9eHc7OzvD19UW3bt1w9erVBx63YsUKCIKAvXv3YujQoQgICEBISEiRYgBASkoKRo8ejYoVK8LJyQkhISHo06cPEhISsGfPHjRp0gQA0L9/fwiCAEEQsGLFioLrjxw5gueeew6enp5wcXFB69atceDAgQee4+OPP4YgCDhz5gx69eoFb29vtGzZsjB/zQ+oWLEisrKyYDKZinwtETkOzmwQlRIxMTGYMWMGduzYgVu3bsFgMKBu3bro3r07Bg0aBGdnZ3unKMutW7ewePFivPLKK8W2POTcuXP49ttvsX37dsTExMDNzQ0NGzbElClT0Lhx42LJgZSxdetWVK5cGS1atCj0Nfv378emTZswdOhQuLu7Y+7cuXj11Vdx7do1+Pr6AgCOHj2KgwcPokePHggJCcHVq1fxzTffoE2bNjhz5gxcXFweiDl06FD4+/tj0qRJyMzMLFKMjIwMPP300zh79izefPNNNGzYEAkJCfjpp59w48YN1KxZE5988gkmTZqEQYMG4emnnwaAgu95165deP7559GoUSNMnjwZGo0Gy5cvR9u2bfHnn3+iadOmD+TarVs3hIaGYtq0aYXae5GdnY3MzExkZGRg7969WL58OcLDwx3+vYeI/oNYSgAQhw0bZu80iOzi559/Fp2dnUUvLy/xnXfeERcvXizOnz9f7NGjh6jX68WBAwcWPNZRXytHjx4VAYjLly8vtud87733RC8vL3HAgAHiokWLxBkzZohVqlQRtVqtuGPHjmLLg+RJTU0VAYidOnUq9DUARIPBIF66dKng9/755x8RgDhv3ryC38vKynro2kOHDokAxFWrVhX83vLly0UAYsuWLUWz2fzA4wsbY9KkSSIAcdOmTQ893mq1iqL4+NeJ1WoVQ0NDxQ4dOhQ8Nv+5K1WqJLZv377g9yZPniwCEHv27PnQ8zzJZ599JgIo+IqIiBCvXbtWpBhE5HgcfhkVO4fYRmRkJF5++WUEBgZCEAR8/PHHxfr8pJz716KfOXMGc+bMwcCBAzFs2DB8//33OHPmDGrXrl2sOeWP2DqCJ+Xas2dPXL9+HUuXLsWgQYMwZswYHDlyBD4+PnzNOJC0tDQAgLu7e5Gua9euHapUqVLw63r16sHDwwOXL18u+L37R+3z8vKQmJiIqlWrwsvLCydOnHgo5sCBAx/av1DYGBs3bkRYWBg6d+78UFxBEJ74vZw8eRIXL15Er169kJiYiISEBCQkJCAzMxMRERHYt28frFbrA9cMHjz4iTH/rWfPntixYwfWrFmDXr16AUCJ+Jwmoidz6GJj27ZtqFu3LtavX4+OHTti3rx5+Oyzz1C+fHmMGTPmketrHU1+55DiLjYmTpyIo0ePokGDBsX6vKQ8rkW/xxZr0Rs1agQ3N7cHfs/X17dgKQs5Bg8PDwBAenp6ka4rX778Q7/n7e2N5OTkgl9nZ2dj0qRJKFeuHJycnODn5wd/f3+kpKQgNTX1oesrVar00O8VNkZMTAzq1KlTpO8h38WLFwEAffv2hb+//wNfS5cuRW5u7kP5PirXJ6lQoQLatWuHnj174rvvvkPlypXRrl07FhxEJZzD7tlg5xB5/ivXK1euoGLFikhISIC/v38xZkZK41p0269F/7c7d+7Az8+vyNeRfXh4eKBMmTKIiooq0nWP66B0/8/MiBEjsHz5cowaNQrh4eHw9PSEIAjo0aPHQzMFAB65f6GoMaTIj/PFF188ds/TvwtruXstunbtiiVLlmDfvn3o0KGDrFhEpGL2Xscl1eDBg0UA4oEDBwr1ePxvHfqPP/4o1q5dWzQYDGKtWrXEX3/99YHHXb16VRwyZIhYrVo10Wg0ij4+PmLXrl3FK1euPPC4/PW1e/bsEYcMGSL6+/uLXl5eRYohiqKYnJwsjho1SqxQoYJoMBjEsmXLir179xbj4+PF3bt3P7C+Nf/r/rW2hw8fFjt06CB6eHiIzs7OYqtWrcT9+/c/8Bz562ujo6PFnj17il5eXmL9+vUL9fcWHx8vAhAnT55cqMeTunAtevGsRb/fvn37REEQxI8++khyDCp+gwYNEgGIBw8eLNTj8z9T/q1ChQpi3759C37t6ekp9u/f/4HHZGdni1qt9oHH5b9Ojh49+lDMwsaoXbu2GBYW9sS8jx079sjXyV9//SUCEBctWvTE60Xx/79O4uPj//OxT7J582YRgLhu3TpZcYhI3Rx2GZXU0dqhQ4eiR48emDFjBnJycvDqq68iMTGx4DH3j7TOnTsXgwcPxs6dO9GmTRtkZWU9FHPo0KE4c+YMJk2ahHHjxhUpRv5o7bx58/Dss89izpw5GDx4MM6dO/fAaC0ADBo0CKtXr8bq1avRqlUrAPdGa1u1aoW0tDRMnjwZ06ZNQ0pKCtq2bYu//vrroVy7deuGrKwsTJs2DQMHDiz03xs5Lq5FL5616Pni4uLQq1cvVKpUCWPHjpUUg+xj7NixcHV1xVtvvYW7d+8+9OcxMTGYM2dOkeNqtdqHZsfmzZsHi8WieIxXX30V//zzD3788ceHYuRfnz+jnZKS8sCfN2rUCFWqVMGXX36JjIyMh66Pj48vdL6FvXbZsmUQBAENGzaUHJvUja3UCXDQZVRpaWm4efMmOnXqVKTrzp49izNnzhTcRD3zzDMICwvD999/X/BiePHFF9G1a9cHruvYsSPCw8OxceNG9O7d+4E/8/Hxwc6dOx+4iSpsjC+++AJRUVHYtGnTAzdREydOhCiKEAQBzz//PCZNmoTw8HC88cYbBY8RRRGDBw/GM888g19//bXghuvtt99G7dq1MXHiRGzfvv2BHMLCwrBmzZoi/Z2RY7P1WvTPPvsMy5cvx82bNx+4GSrKWvTCxIiJicGrr75apO8h3/1r0R8nNTUV3t7eT8z1v2RmZuKll15Ceno69u/f/9CSE1K3KlWqYM2aNXjttddQs2bNB04QP3jwIH744Qf069evyHFfeuklrF69Gp6enqhVqxYOHTqEP/74o2A5opIxxowZgw0bNqBbt25488030ahRIyQlJeGnn37CwoULERYWhipVqsDLywsLFy6Eu7s7XF1d0axZM1SqVAlLly7F888/j9q1a6N///4oW7Ysbt68id27d8PDwwNbt24t8vcP3Gs4cuDAATz33HMoX748kpKSsHHjRhw9ehQjRoxA1apVJcUl+2Erddv77rvv8MYbb8DV1fWRAwCOxGGLDaB4RmvT0tIeGGn9d7FRmNHax8VQYrR24sSJD8zMAEBERARWr14Nq9UKjeb/T15JHa0lx8W16MWzFt1kMqFLly44deoUfv/9d8mbdMm+Xn75ZZw6dQpffPEFtmzZgm+++QZOTk6oV68eZs6cKWlGeM6cOdBqtfjuu++Qk5ODp556Cn/88UeR9igUNoabmxv+/PNPTJ48GT/++CNWrlyJgIAAREREFDRl0Ov1WLlyJcaPH4/BgwfDbDZj+fLlqFSpEtq0aYNDhw5h6tSpmD9/PjIyMhAUFIRmzZrh7bffLvL3nu/FF19ETEwMvv32W8THx8NoNKJevXpYvnz5EwcBSJ22bduGbt26wcnJ6YGifP/+/RgzZgyio6OxePFie6cpS35znooVK9ql2MjIyCiYbS0JHLLY4Ght8Y3WkuN76aWXsHjxYhw6dAjh4eGKxd2wYQP69u2LmTNnFvxeTk7OQ8szlIhRpUqV/yyYHleg5w8weHh4oF27doXOrbCsViv69OmDnTt3Yv369WjdurXiz0HFJzQ0tFA3Sv9e1pTv353UvLy88O233/7n4/r16/fYmZPCxgDuzbbPmzcP8+bNe2Qs4F5R9fLLLz/yz+rXr4+NGzc+9lrgXte2orR2bt++Pdq3b1/ox5N6sTmPPIXN9dNPP4W7uzueeeYZbN682faJ2ZhD7tmw9WhtZGQkunfvjvXr12P79u3YsWMHfH19izRaW5QYUtw/Wrtjx45HfindOYQcE9ei224tOnDv9b5u3TosWLAAXbp0kRWLiEjN2Er9Hlu0Us938eJFzJo1C1999RV0OoecE3iIw34XHK217WgtlRxci267teizZ8/GggULEB4eDhcXF/zf//3fA3/euXNnhxlxIyL6L2ylbvtW6qNGjcIzzzyDF154AevXry/037OqFX8DLGVcunRJdHV1FWvVqiXeuXPnkX8+e/bsgl+jkG0KfXx8xH79+j3wmBkzZogACt2msLAxCtPO8+zZsyIAcdasWQ/8ucViEatUqSKGhoaK6enpD10fFxdX8P9y2hSy9W3JceHCBXHgwIFixYoVRYPBILq7u4tPPfWUOG/ePDEnJ6fgcYV9rSQnJ4v9+/cX/fz8RDc3N7FDhw7iuXPnHnrck14rhY0hiqKYmJgoDh8+XCxbtqxoMBjEkJAQsW/fvmJCQkLBY7Zs2SLWqlVL1Ol0D7X3/Pvvv8UuXbqIvr6+opOTk1ihQgWxe/fu4s6dOwseU9TXSt++fR/Znjr/61HtromIHBFbqdu+lfrPP/8s6nQ6MTo6WhTFe58xrq6uhb5erRx2ZoOjtbYbrQWA1atXIzY2tqBV7759+/Dpp58CAHr37o0KFSpIjk32wbXoyq9FX7FixQNT60REJRWb89i2OY/JZMLo0aMxePBg1KpVq1DXOAqHLTYAdg6xVecQ4F7/87179xb8evfu3di9ezcAoGXLliw2iIiIShE257Ftc55Zs2YhISEBU6ZMkZSbmjl0sQFwtNYWo7UAsGfPniI9noiIiEoutlK3XSv11NRUfPrppxg6dCjS0tIKZpEyMjIgiiKuXr0KFxcXBAQEyPsG7MThiw0iIiIisj0257FNc57k5GRkZGRgxowZmDFjxkN/XqlSJXTq1Mlh2+A6ZOtbIiIiIipebKVum1bqAQEB+PHHHx/6euaZZ2A0GvHjjz9i/PjxkmKrAWc2iIiIiOg/sTmPbZrzuLi44JVXXnno9zdv3oy//vrrkX/mSFhsEBEREVGhsDmP7ZrzlFSC+Lid00RERERERDJwzwYREREREdkEiw0iIiIiIrIJFhtERERERGQTLDaIiIiIiMgmWGwQEREREZFNsNggIiIiIiKbYLFBREREREQ2wWKDiIiIiIhsgsUGERERERHZBIsNIiIiIiKyCRYbRERERERkEyw2iIiIiIjIJlhsEBERERGRTbDYICIiIiIim2CxQURERERENsFig4iIiIiIbILFBhERERER2QSLDSIiIiIisgkWG0REREREZBMsNoiIiIiIyCZYbBARERERkU2w2CAiIiIiIptgsUFERERERDbBYoOIiIiIiGyCxQYREREREdkEiw0iIiIiIrIJFhtERERERGQTLDaIiIiIiMgmdPZOgIiIiEoGk8mEuLg4/P3337h06RKys7Ph7e2N2rVro06dOvDy8oJGw3FOotKExQYRFStRFP/zMYIgFEMmRPYnimLBa+Lf/5//X5PJBLPZDLPZDIvFAqvVCovFIus5zWYz8vLyYDKZYLVaFfk+kpKS8MMPP2DLli1ITEyE2WyGKIrQaDTQ6/WoXLky+vTpg/79+8Pf31/2cxKRYxDEwnzyk6qYTCbk5uYiJycHubm5SE9PR2JiItLT05GZmYmsrCzk5OTAbDbDarVCq9XCYDDA1dUVbm5u8PX1hb+/P1xdXeHs7AxXV1fo9Xp7f1tUAqWnpyMqKgrR0dG4fPkybt++jaSkJKSnp8NkMhXcMGk0Gmg0Gri4uMDLywtBQUEoW7YsypUrh7JlyyI4OBhly5aFi4uLnb8joqKxWq1IT09HWloaUlNTkZGRgbS0NKSnpyMlJQWJiYlISkpCSkoKkpOTCx6TkZGBzMxM5OXlwWq1FhQi93/JkR8jP7YS8vLykJ6e/sR4Op0OzZs3x+zZs9GoUSNFnpeI1I3FhoqZTCakpaUhOTkZMTExuHTpEi5fvowbN27g9u3biIuLQ0JCArKysh74MAIePXosCAIEQYBGo4FWq4WHhwfKli2LatWqoXHjxmjbti2qVq0KNze34v5WqYRJT0/Hxo0bsWTJEkRFRSEtLU1yLBcXF/j4+CAwMBB169ZFy5YtERYWhooVK8LX15ezIGRXGRkZSExMREpKClJTU3Hr1i1cv34dN27cwM2bN3Hz5k1kZGQgOzsbOTk5yMnJQXZ2NnJzc2XNTji6GjVqYNWqVWjSpIm9UyFSPVEUkZycjBMnTuDy5cuwWCxwdXVFWFgYqlevDqPRaO8Un4jFhopYrVYkJSXh8uXL2LdvH44cOYIzZ87g2rVrBR9MSkx3P4pGo4GbmxtatGiB3r17o0OHDvD19bXJc1HJFhsbi7Fjx2Lz5s0wmUw2eQ5PT0+UK1cOtWrVwtNPP43w8HCEhobCw8PDJs9HBNx7j05OTsaNGzfw119/4ciRI7h06RLu3LmDuLg4pKWlleoCoqiaN2+OH3/8EUFBQfZOhUi1MjIy8P3332P+/Pm4dOkSsrKyAKBg0Lh169b44IMP0LRpU9Xuh2KxYWdmsxl37tzBsWPH8Ntvv+HQoUO4cOECcnNzFZvaLiq9Xo8GDRrg7bffRqdOnVh0UKHdunULffr0wa5du4r159fDwwP16tVD9+7d0alTJ5QrV44zHqQIq9WKtLQ0/PXXX/jtt99w8OBBnD59GtnZ2XZ7jy4pNBoNIiMj8cEHH/D1SvQIaWlpGDt2LFasWIHc3NzHPi4oKAhz585F165dVflaYrFhBxaLBbdv38bhw4exZcsW7N+/Hzdu3IDZbLZ3ag/Q6XRo3Lgx3nvvPTz33HNcXkVPZDKZ8O677+Kbb76x2QzcfxEEAaGhoRgwYAD69u2LwMBAu+RBJUNSUhJWrVqF5cuX4+LFi8jJyWGBobD69evj119/5ewG0b9YLBZ89NFH+OKLLwp1fxgQEICNGzeiZcuWxZBd0bDYKCaiKCIhIQFHjx7Fpk2bsHv3bsTGxjrElLuTkxNeeOEFjB8/Hg0bNoRWq7V3SqRChw8fxvPPP4+UlBR7pwKNRoOGDRvio48+QocOHeDk5GTvlMjBnDp1CqNGjcL+/fuRl5dn73RKLIPBgD179iA8PNzeqRCpytGjR9GhQwckJycX+poOHTpgw4YNqhscVufirhIkIyMDhw8fxtixY9G2bVu88sorWLZsWcEGH0eQm5uLH3/8ES+++CIiIyORkJBg75RIZdLS0rBq1SqkpqbaOxUA95a+HDt2DK+//jrGjh2LGzdu2DslciBRUVF48803sXv3bhYaNmYymXD27Fl7p0GkOmvWrClSoQEA+/fvx6lTp2yUkXQsNmzAarXi6tWrWLRoEV5++WW0b98eX375JaKiohz6gys+Ph5TpkzBK6+8gn379tltqQyph9lsxp49e9CrVy8sW7ZMdUtMMjIyMH/+fHTu3Bk7duxw6NcfFY/09HSMGzcOx48ft3cqpUZSUpK9UyBSldTUVOzbt6/I12VnZ+PIkSM2yEgeFhsKysrKwp9//olhw4bhmWeewZAhQ7B7925kZGTYOzXFWK1WHDhwAF26dMGsWbMKuiJQ6ZOamorIyEi8+uqr2LZtm806T8mVP8vRo0cPfP7557La8FLJJooifvzxR+zcudPeqZQqrq6u9k6BSFViY2Nx/vz5Il9ntVpx584d1Q388QRxBaSkpGD79u1YtmwZDhw4gMzMTHunZHOJiYn48MMPER0djenTpyMgIMDeKVExun37Nt577z388MMPqmts8DhJSUmYOnUqoqKiMGPGDJQvX97eKZHK5ObmYsWKFcjJybF3KqWGIAioWrWqvdMgUpVjx44hOztb0rVOTk6q60jFYkOG5ORkbNmyBQsXLsSJEydK3RINk8mEFStWICEhAYsWLUJwcLC9U6JicOPGDQwaNAi///67wy2lM5lM+OGHH3D9+nV8/fXXqF+/vr1TIhW5du2aKtc7l2QVKlRAaGiovdMgUpVTp05J+nzV6XSoVq2aDTKSh8uoJMg/YOWFF17AwIEDceTIkVJXaOQTRRE///wzRowYgcTERHunQzZ29+5dDB482CELjXxWqxUHDx5Ez549i/08EFK3CxcuSB5NpKITBAEvvfQSQkJC7J0KkWqYTCbExsZKutbd3R1NmzZVOCP5WGwUgdVqxf79+9GtWzf0798fhw8fdpglJLaUv855/Pjx3MNRgqWlpeG9997Dr7/+6rCFxv3OnTuHfv364aeffmLBQQDuLYl1lC6BJUGFChUwdOhQ6HRcZEGUz2Qy4c6dO5KurV69uipXmbDYKKT4+HhMnDgRnTt3xm+//fbEkxxLI6vVilWrVuH//u//eONWAplMJnz22WdYv359iSg08l2/fh2DBw/Gli1b+HNLcHV1hUbDj8Xi4ObmhqlTp6J69er2ToVIVcxms+TzqipVqgQXFxdlE1IA31X/gyiK2L9/P7p06YLPP/+cZ0w8QW5uLubNm4e4uDh7p0IKEkURq1evxvz580vkcsE7d+5g+PDh7EBEqFKlCg+ALAZOTk4YNWoUunfvzuKO6F8sFovkVSK+vr6qPHiZr/InyM3NxZIlS9C9e3fs37+/RI3o2sr58+dx+PBhe6dBChFFEX/88Qc++uijEtXC+d9u3ryJkSNHIioqyt6pkB1VrlyZnZFszMXFBaNGjcIHH3wAg8Fg73SIVMdqtUruiOfu7q5wNsrgQsnHSE5OxieffIJFixapbsOgIAgQBAEajQZ6vR4+Pj7w9fWFh4cHXF1dYTQa4eTkBK1WC41GU/CDm52djbS0NCQlJeHmzZvIyMhQfOmI2WzGkSNH0KlTJ0Xjkn2cPXsWo0aNwu3bt236PAaDAVqtFiaTyW5r5s+cOYMxY8bgu+++g4+Pj11yIPtydXXF66+/jpMnT3I/nsIMBgPq1KmD0aNHo2vXrjAajfZOiUiVRFGU/P6j1plZFhuPcOPGDbzzzjv46aefVLFZUKvVws3NDaGhoahSpQoqVaqEKlWqoHLlyihbtmxBgWEwGKDX66HVagsKjXxmsxlmsxkmkwk5OTm4efMmVq5cifXr1+Pu3buKFR2iKCI+Pl6RWGRfcXFxGDlyJM6cOWPT53Fzc8Mnn3yCBg0aICMjA3Fxcbh27RrOnj2LM2fO4O7du0hKSiqW1+KOHTswffp0fPrppxx1LYUEQUCvXr2wbt06h5+hzf/ceJz8Aav8wSsl5MfM/wxycXGBv78/6tatizZt2qBNmzY8k4noP4iiKPmeTK3LElls/Mvly5fx1ltvYc+ePXbdMGowGBASEoIWLVrgmWeeQYsWLRAUFAQ3NzdJnTv0ej30ej2cnZ3h6emJwMBA1KtXD2+//TYWLFiA7777TvKGpEc9Fzm27OxsTJ06Fbt377bp8zg5OWHo0KEYOnToQyMyoigiMzMTFy9eRFRUFA4dOoQjR47g2rVrSExMtMnr02KxYOHChWjYsCFee+011R2MRLYXEBCAzz//HL1798a1a9dkx7v/Blyj0UCj0UCn08HT0xO+vr7w9vaGj48PvL294enpiaNHj+LPP/+U/fMdGhqKhQsXPvLmQxAEaLVa6HS6gllFufK/LycnJzg7O8PFxaXgcLH875uISicWG/e5cuUK+vfvr8gbvRQGgwEVK1ZEREQEXnjhBTRu3Bi+vr42u3nX6XSoVasWvvrqK3Tr1g2RkZHYs2ePrE3AGo2GBzQ5OKvVirVr12LZsmU2nU3w9fXF8OHD8f777z9y6lcQBLi5uaFBgwZo0KABXn/9dZhMJpw9exZr167F8uXLbTKLlp6ejvHjxyM0NBSNGjVSPD6pX8uWLbFo0SKMGDECly5dKtQ1+TfwgYGBCA4Ohp+fH/z9/REYGIgyZcogODgYQUFB8PPzg5+f3wNLXXU6XUFB8t577+HPP/+U/T0EBwejdevWsuMQ/VtOTg6uXr1a0DDH19cXFStWhLOzs50zKxny30ukUOvyTxYb/5N/KnJxFxp6vR7BwcGIiIhAp06dEB4eXuzdBAwGA1q3bo2wsDAsX74cX375JW7duiUplqurK1q1aqVwhlSc/v77b0yePNkme5V0Oh18fX3Rpk0bDB48GE8//XShf9Y1Gg2MRiMaNGiAunXr4qWXXsLEiRNx8OBBxd9gr169ilGjRuH777/ngWOlkEajQYcOHbB161bMmjULW7duxZ07dx76bNDr9ahUqRIaNmyINm3aoFGjRggICICLiwuMRiOMRmORZqJFUURKSooin0H+/v6yYxDlM5lMyM7OxtatW7F06VJER0cjOTkZoijC29sbNWvWxMCBA9GlS5cnLt+j/yan2FBrx0gWG7h3hsaIESOwc+fOYik0NBoNvLy80KpVK3Tu3Blt27ZFYGCg3ZcfeXl5YeTIkWjRogVGjRqFI0eOFPnvo0OHDqhVq5aNMiRbS0pKwoQJE3D9+nVF47q4uKBly5bo0qULIiIiUL58eVl7InQ6HZ5++mls2LABs2bNwjfffKPYMsB8Bw8exIQJE/D111/zw7MUEgQBNWrUwPz58zFixAgcPnwYJ06cQFxcHAwGA6pUqYLw8HDUrl0bISEhigwQmUwmpKWlKZD9vdFmIjlEUcS1a9ewceNG/PHHH7h48SKuX7/+0DljiYmJ2L9/P44ePYodO3bgyy+/RGBgoJ2ydnyCIEi+HzSZTApnoxCxlEtJSRH79+8vajQaEYBNv4xGo1i/fn1x6tSp4unTp8Xs7Gx7f/uPdeHCBbF58+ZF+v4qVKggHj9+3N6pk0RWq1WcOXOmqNPpFP25Dw4OFtesWSOmp6fbJG+TySRu3LhRrFy5suKvWScnJ3HGjBliXl6eTXInul9aWprYvn17RX52P/roI3t/O+TA8vLyxDVr1ojVqlUr0v2RIAjiSy+9JF6/ft3e34LDSkxMlPx5NmzYMHun/0ilesdWRkYGpkyZgtWrV9vsDA1BEODr64sePXpg3bp12LVrFyZMmIA6deqouvVfaGgolixZgsaNGxdqk2xISAjmzp2LBg0aFEN2ZAvnz5/H3LlzFV2S5OPjg7lz5+K1116z2eyAXq9H586dsW7dOjRt2lTRTd25ubmYMWMG9u7dq1hMoscxm82KLV9k+2aSShRFrFy5EoMHD8aFCxeKdH8kiiK2bduGAQMGKNJgoTTSaDSSZ/6lHgZoa6W22MjLy8PcuXPx9ddf22RDjSAIKFOmDN555x388ccfWLlyJV5++WV4e3s7TIebOnXqYP369ejXr99j83ZxccGzzz6L9evXo2PHjg7zvdGD8l8PsbGxisV0cnLCxIkT8corr9i8E40gCGjcuDHWrFmD9u3bKxo7ISEB48aNk7yPiaiwzGaz5MO8/s3Dw0OROFT6nDx5EhMnTpS8pE8URezYsQN9+/bFlStXFM6u5NNoNHB1dZV0bUZGhio3iZfKPRv53XamT59uk/VtgYGB6NWrFwYOHIjQ0FBJrWrVolKlSli4cCEGDx6M33//Hf/88w+SkpLg4uKCmjVrIiIiAi1btuSadgd37NgxrFu3TrF4Go0Gb775JgYOHFisP/9VqlTBsmXLMGjQIPz666+KxT1x4gTmzJmDTz/91O57q6jkslgsin0mubi4KBKHSher1Yqvv/4ad+7ckRVHFEXs3bsXffr0wfLly1G1alWFMiz5NBqN5Huq/GJDbfed6sqmmBw8eBDjx49Henq6onGNRiOef/55TJgwAWFhYar7x5bKYDCgadOmaNKkCcxmM6xWKwRBKGjXSI7NZDJh3rx5SEpKUiSeIAjo0KEDPv74Y7sUoSEhIZgzZw6uX7+OqKgoRWJarVYsXboUHTt2RMuWLRWJSfRvZrP5oc23UrHYIClu3bqFHTt2KBJLFEXs378fvXv3xvLly1GjRg1F4pZ0er0e7u7ukq5NT09X5cxGqbtTjI2NxejRo3Hz5k1F45YpUwZffPEFVq1ahUaNGpWYQuN++R0SnJycYDAYWGiUEIcPH8Yvv/yiWLzatWtj9uzZdj0pODQ0FF9++aWi69aTkpIwbdo0xQcpiPJZrVYWG2RXhw4dwo0bNxSNefjwYfTu3VuxwZ+STqvVSi420tLSVNn+tlTdLaalpWH8+PE4fvy4YjEFQUCjRo2wbt06DB06lMuJyKGYTCYsWLAAqampisQLDAzE3LlzUa1aNUXiyREREYExY8Youuxp586d2LJli2LxiO5nsVgUuVEQBEHVDUhInSwWC3755RebNMw5duwYevfujdOnTyseu6TR6XTw8vKSdG1ycjKLDXvKy8vD7NmzsWHDBsXO0tBoNHjxxRexfv16tGzZkiP95HAOHTqE3377TZFYRqMREydOVM2pxTqdDsOGDUP37t0Va1xgMpkwf/58m5xcTqTUng2dTlciZ9fJtvLPy7CVkydPonfv3jh16pTNnqOkkHpOTmpqKjIzMxXORr5ScXcsiiK2bNmCmTNnKlbxCYKATp06YcmSJahcubIiMYmKU/5eDSVmNTQaDXr06IE333xTVUW3u7s7pk2bhmbNmikW89ixY/jpp58Ui0eUz2q1KvIZpdfrFTlkkEqXU6dOKb6E6t/++ecf9OnThwXHfwgMDJT0WWoymXD79m0bZCSPeu4KbCg6Ohrjxo1T7GRWQRDw7LPPYv78+QgKClIkJlFxO3jwIP744w9FYoWGhmLSpEmqXCdevnx5zJkzBxUqVFAknsViwdKlSxXbUE+Uz2q1KrK5U6vVstigIsnfzK3UnqEnyS84uKTq8cqVKydpRt5isdi8YJSixBcbKSkpGDduHGJiYhSLGR4ejgULFqBMmTKKxSQqTmazGUuXLlVkVsNgMGDUqFGoWLGi/MRspHHjxpg+fbpiZw+cOHEC+/btUyQWUT6r1QqLxSI7jlarVdUMI6lfXl4e/v77b8WWmf+X/IKDm8YfLSQkRNJr2GKxqPJMqBL9bmSxWDB//nz8/vvvisWsU6cOFi1axKVT5NCioqIUa2/YpEkT9OjRQ9UHOmo0GnTp0gWDBw9WZC27yWTCqlWrVLkRjxyX1WpVZHOuRqNhsUFFkpOTgzNnzhTrc548eRJ9+/Yt9ud1BD4+PpIGx6xWKxISEmyQkTwl+t3o0KFDmDt3rmI9hytWrIglS5agTp06isQjsgdRFLFx40ZFNjk7OzvjnXfekdw5ozgZDAa89957aNy4sSLx9u/fzw9JUpxSxYaai39Sn/j4eKSkpBT78544cQJ9+vTBuXPniv251czFxUXy52pSUpJNOorJUWKLjZSUFEyZMkWxrjE+Pj6YN28emjdvrkg8IntJSEhQrCtbkyZN8PzzzyuQVfEICAjAhx9+KLmH+f3i4+OxdetWBbIi+v+UuEkQBIHFBhVJXFxcsezXeJTjx4+jf//+uHTpkl2eX42cnJxknSLOYqMYiKKIb7/9Fnv37lUknpOTEyZPnuxQN1VEj/PHH3/gypUrsuMYjUYMHTpUkRv34vTss8/i5ZdfViTWli1bFGs8QSSKoiKDACw0qKji4+PtVmwA9w7+69+/Py5fvmy3HNREp9PB2dlZ0rUZGRnFtvemsEpksREdHY3Zs2crdjhS3759MXDgQHb3IIdnMpmwdu1aRT5UmjVr5pAFuJOTE9555x34+fnJjnXu3DlFDwklYrFB9pCamirpnknJWbQDBw5gwIABuHbtmiLxHJler5d8MGdWVhZnNmwtOzsbkZGRuH79uiLxWrdujSlTpkiuMInU5Pz58zh06JDsOE5OThg2bJhi3Z2KW8OGDfHiiy/KjpORkYEtW7aobhSJiKgozGazpPcxDw8PdO/eHU5OTrJzEEURe/fuxdtvv63KsyKKk5xiIzs7W3WfSSWu2Ni4cSO2bNmiSKzKlStj9uzZPEuDSgRRFPHLL78gMTFRdqzGjRvj2WefVSAr+9DpdOjTp48ixdLvv//OE8WJyKFJvTl1cXHBpEmT8MEHHyhWcPz+++8YMWKEIp9Vjkqj0Uj++8zJyWGxYUtXrlxBZGQksrOzZcfy8PDAl19+ibCwMAUyI7K/zMxM/PTTT7KnVwVBQO/eveHp6alQZvYRHh6OevXqyY5z5coV/PnnnwpkRETkWPR6PTw8PDB+/HhFC44ff/wRY8aMQXp6ugJZOiapMxsmk4nFhq2YTCZMnz4d58+flx1Lq9Vi1KhR6NixowKZEalDdHQ0oqOjZcepXLkynnvuOQUysi9nZ2f07NlT9nkEubm5WLdunWIttomIHIVGoylY8jNu3DjFCg6r1YrVq1fj008/tevGdXuSM7PBPRs28vvvv+P7779XpJpr3749Ro0apcjhX0RqIIoitm/frsgo0fPPP4/y5csrkJX9tWvXDmXKlJEdZ9++fewTT0Slzv2n1Ts7O2P8+PEYO3YsDAaD7Nhmsxlz587FwoULYbFYZMdzNHJmNtSmRBQbCQkJmDZtmiI3UkFBQZg6dSq8vb0VyIxIHTIzM7F9+3bZox2urq7o2bNniel2U7VqVbRo0UJ2nLi4OGzcuFF1o0lERLZksVgeeN8zGo348MMPMWbMGEUKjpycHHz88celshGH1JkNLqOygfwzNY4ePSo7llarxciRI9GwYUMFMiNSj0uXLuHUqVOy4zRp0gR169ZVICN10Gg06Nq1q+xZTFEUsXbt2lK9oZGISh+z2fzQSHp+wTF69GhFCo6UlBS8++67+Ouvv2THciRSZzasVqvqlvU6fLFx8eJFLFiwQJEptqeeegqDBg2SvYabSE3yl1BlZmbKiiMIAl5++WWHO8Tvv4SHh6NKlSqy41y+fBm//PKLAhkRETmGvLy8R+6pcHFxwcSJEzFixAhFlqTHxsZi+PDhuHr1quxYjkJqoSaKIosNJVmtVixcuFCRA2C8vb0xadIk+Pj4KJAZkXpkZmbijz/+kF2Qe3t7o0OHDgplpR4hISFo166d7DgmkwmrV69GVlaWAlkRERUfqUtjs7KykJGR8cg/c3Nzw8cff4whQ4YoUnAcO3YMo0aNQkpKiuxYjkDqQdKiKKpuSa9DFxtnzpzB2rVrZa9NEwQB/fr1Q5s2bZRJjEhFrl+/rsgyw0aNGpWYjeH/1rVrV7i4uMiOc/ToURw7dkyBjIiIio+zs7Okm9usrCykpaU99s/d3Nwwbdo0DBgwQJGCY+vWrZg8eTJycnJkx1I7OXsjuWdDIaIoYuXKlYqcMhkWFoZ3331XchVJpGY7d+6U3TxBEAS0b98ebm5uCmWlLg0bNkSDBg1kx0lLS8MPP/yguilsIqIn8fHxkbRsx2Kx4O7du098jJubG6ZPn45evXrJvs+yWq1YtGgR5s6di7y8PFmxqPg4bLFx9epVbNiwQXYcd3d3TJo0CSEhIQpkRaQu2dnZ2LVrl+wlVG5ubg59Yvh/8fDwQI8ePRTpsvXzzz8jLi5OgayIiIqHr6+v5D0ChdlH4eXlhZkzZ6Jjx46y32dzc3MRGRmJNWvWqG65kJLkfG9q6xjpsMXGli1bEBsbKyuGIAjo0aMHXnzxRYWyIlKXhIQEHDlyRHacsLAwVKxYUX5CKvbCCy+gQoUKsuPcunULO3bsUCAjIqLi4e/vL7nV6pUrVwr1OD8/PyxYsACtW7eW9Dz3S0tLw5gxY0p0Uw6pM+SCIKiu0ZG6simk9PR0rFu3TvaatCpVqih2+AyRGh0/fhzx8fGyYmg0GkRERMDT01OhrNSpYsWKigw8mEwm/Pzzz6ViTTERlQze3t7w8PCQdO3Vq1cLPXseHByMRYsWISwsTNJz3S8+Ph5DhgzBnj17ZMdSIznFhtoOpXbIYuPEiROyzwwwGAwYPXq0Ii0vidTIarVi165dste1Go1GPP/88wplpV4ajQa9e/eW/IF7v3379uHWrVsKZEVEZHt6vV7ycvJbt249cZP4v1WrVg0LFixQpOHIjRs3MHDgQBw8eFB2LLXJzs6WdJ1Wq2WxoYQff/xRdnvJpk2bolevXqpb10aklNTUVEW6UNWqVQvVqlVTICP1q1u3Llq1aiU7TnJycokdbSOikken00m++b916xZSU1OLdE14eDi+/PJLRWbML126hAEDBpS4Q/+kno3l5OSkuntbhys24uPjsXPnTlkxjEYjhg8fDi8vL2WSIlKh27dv48yZM7JiCIKANm3alPglVPlcXFzw+uuvyx4VysvLw65dux46WZeISI10Oh2qVq0q6dqUlJQidwYVBAGdO3fGhAkTFFnKfu7cOfTt21eRATa1eNz5Jf/F1dWVezbkOnXqFC5cuCArRlhYGJ577jmFMiJSp6NHj0p+s8rn5OSEiIgI1b1x2VLr1q0lf+je78CBA0hMTFQgIyIi26tSpQr0en2Rr7NYLDh79myRr9PpdBgxYgT69++vyGfMuXPn8MYbb+DQoUOyY6mB1GVUzs7OnNmQ69dff5U1WqjT6fDGG28osi6bSK1EUcT+/ftltwUMCgpS5PwJRxIYGIjnn39e9pv1rVu3ZO8tIyIqLqGhoZKKDavVKqnYAO6tNPn000/RoUMHRW6QL1y4gN69e+OPP/5Q3cF2RWE2m5GbmyvpWmdnZ9UNEKorm/+QkpIiex10UFCQIn2eidQsJSUFp0+flh2nWbNmpW65oUajwSuvvCK5DWS+vLw87Ny506E/8Iio9AgJCZG8ZPbChQuSb479/Pwwd+5cNGrUSNL1/xYTE4N+/fph8+bNDnsOh9lsljyw7uLiorp7XIcqNi5evIhz587JitG2bVuULVtWoYyI1Ck+Ph4XL16UFUOr1SI8PFz2Tbcjql27NqpXry4rhiiKOHLkSJG6tBAR2Yubm5vks4ZiYmIkL/sBgKpVq+Kbb75B5cqVJce4382bNzFw4EB89913sg+1tQc5MxtGo5HFhhy7d++WvDsfuLf+/MUXX1RdSzAipV2+fBnJycmyYjg7O6NZs2YKZeRYvLy80LJlS9lxTp8+jbt37yqQERGRbbm4uEg+DuDmzZuy96g1btwYCxcuRGBgoKw4+RITEzFs2DB88803Dtesw2KxSG5bzz0bMuTm5sruQhUQEKDIDQSR2v3zzz+yl+8EBQXJHt13VFqtFm3btpXdJSUtLQ3Hjx9XKCsiItvRarWoUaOGpGtzcnJw6dIl2Tm0a9cOs2fPhre3t+xYwL1DoMeNG4evvvpK8kyBPVgsFs5s2MONGzdkr0Fv2bIl/P39FcqISL2io6Nlx2jcuDFcXV0VyMYxNW3aFD4+PrJiWCwW/Pnnn9y3QUQOoU6dOpI2F+fm5uL8+fOyn18QBHTr1g3Tp0+Hu7u77HjAvfMqPvnkE3zxxRcOM8NhNpuRk5Mj6VrObMjwzz//yFqOoNfrERERIanTApEjycjIwJUrV2TFEAQBYWFhivQ/d1S+vr5o0qSJ7DinT5/mvg0icghVq1aFs7Nzka8TRRFnz55VZH+EVqvFm2++iU8++QQuLi6y4wH32shGRkZi1qxZkpcnFSeTySR5ZoPnbMiwe/duWV0FPD098fTTTyuYEZE6JScn486dO7JiGI3GUruEKp+zszNatGgh+037woULSEhIUCgrIiLb8ff3R3BwsKRro6KiYDabFclDp9Nh2LBhmDx5smIFR05ODj755BMsWrRIsTxtRc7MhhpXJDhEsZGamir7VMiwsDCUK1dOoYyI1Cs5OVn2pmSj0YjQ0FCFMnJcLVq0gNFolBUjISFB9kGkRETFwcfHByEhIZKujY2NVXQWV6/XY/To0Zg0aZJiN9BZWVn46KOPsH79elW3xc3Ly5PU3UsQBLi5udkgI3kcoti4efOmrLWAgiCgTZs2sm8aiBzBtWvXkJ6eLiuGh4cHi3MAtWrVkr3Py2q14vDhwwplRERkO3q9HjVr1pR0bWpqKq5evap4PqNHj8bkyZMVKzhSUlIwZswY/Pnnn4rEs4Xc3FxJy6g0Gg2LDalOnjyJ1NRUyde7uLigZcuWqtswQ2QLcs+iAYDKlSuXyvM1/s3NzQ0NGzaUHef48eMOszGRiEq3sLAwSddlZGQo0pHq3wwGA0aNGoXIyEjFNo3funUL77zzjuLFkVIyMjIkNRZhsSHD4cOHZXVzCQoKQp06dRTMiEi9zpw5IztG9erVeR4N7p3N07BhQ9kDFRcvXkRcXJxCWRER2U6NGjUkNQexWq04deqUDTK6N8MxfPhwzJkzR3aXwHynTp3C+++/r8oGHunp6ZLue7mMSqKMjAxERUXJitG0aVN4eHgolBGReplMJly+fFlWDEEQEBoaymID9/4u6tevL6k7y/1iY2Nx8+ZNhbIiIrKd8uXLw9fXV9K1f//9t832Qmi1WvTt2xeLFy9GmTJlFIm5ZcsWzJw5U3UdqrKysiRdp9FouEFciuTkZFk3T1qtFs2bNy/VLTyp9EhMTJS9OdzJyQmVKlVSKCPHFxYWJnvqPjc3V3aTCyKi4hAcHCz5FO8rV64gOTlZ4Yz+P41Gg86dO2P58uWoWLGi7HhmsxmzZs3CDz/8oKrzkOTMbCjVvUtJqi827ty5g9u3b0u+3mg0KtIrn8gRJCYmym6z6uLiosibeEnh5+enSGcuuctBiYiKg8FgkLxJ/M6dOzafxdVoNGjfvj3WrFkj+cTz++WfMn78+HEFslOGlE5UAIsNyeT2bfbz80PVqlUVzIhIveLj42WPKrm5uaFChQoKZeT4DAaDIgMWZ8+eRUpKivyEiIhsSKPRSG6MkZaWpshJ4v9FEASEh4djzZo1iuzJvX79OkaPHo34+HgFspMvOzubMxvFKTo6Wtb6v1q1aqly/RqRLcTExMg+wTUkJESVG8zsRavVomHDhrKXYnLfBhE5ilq1aknuSFicS0YbNGiAFStWKDLDcfDgQXz22Weq2L8h9UA/jUajym0Dqi428vLyEBMTIytGjRo1eL4GlRpKtB0MDQ2FVqtVIJuSo169erL3bSQlJdmkLSQRkdKqV68u+T3v5MmTxdrqu1GjRliyZInsGXmr1YolS5Zg69atCmUmndQVPVqtVpWf36ouNjIzM2Xt19DpdKhduzY0GlV/m0SKUaJneNWqVfma+ZfKlSsjKChIVgxRFFW1JpiI6HECAwMlnyR+8eJFJCYmKpzRkz311FOYP3++7La4GRkZGD9+fLEsBXsSqSt61PrZrc6s/icrK0vW+jm9Xo/q1asrmBGRepnNZtnLdLRaLSpWrMgDMP/FaDQqcrjf33//zU3iRKR6RqMR9erVk3Tt7du3cePGDYUzejJBEPDCCy9g0qRJsg+kvXDhAsaMGcM9dgpSdbGRk5Mja7OrwWBA+fLlFcyISL3S09Nlvzm6uLggODhYmYRKEJ1Oh8aNG8suwq5fv27TtpBERErQ6XQICwuTNFKel5eHv//+2wZZPZlGo8GgQYPwxhtvyB7h//XXXxEZGVmsy8FKMlUXG1lZWcjIyJB8va+vLzeHU6mRmpoq6/UCAM7OzggICFAoo5JFiWYTcXFxuHPnjkIZERHZTv369aHX64t8ndVqtenhfk/i7OyMqVOnokWLFrLimM1mfP3111i2bJldvo+SRtXFRkpKiqwlBz4+PjwFmUqNjIwMyaeO5jMajfDz81Moo5IlNDQUnp6esmIkJyfLPgeFiKg4VKtWDV5eXpKuPX36tOzPI6mCg4Mxd+5c2edFZWdnY+LEidi+fbsyiZViJbrY8PT0VOWufCJbUKLYcHFxgbe3t0IZlSxyTtXNl5ubK6vpBRFRcfHy8pJ8oOnFixftumS0fv36+PLLLxXpIjhy5EhERUUplFnppOpiQ+6SEHd3d85sUKmRmZkp+dTRfD4+PpKmzUsDnU6HWrVqyY5z9+5dBbIhIrItV1dXyQfmpaWlITo6WuGMCk8QBHTq1AnDhg2TvX/jwoULGDVqVLEugZWas8ViUeWyL1UXG5mZmbJmNpydnTmzQaVGWlqa7AP9uITq8QRBQLly5WTHSUtLUyAbIiLbEgRBcmOM3NxcHDt2zAZZFZ5Op8P777+Pli1byo61e/dujBkzRvYgeGFJPR/OYrGoclO7qosNuaO0RqNRtT2HiZSmRJs+Hx8ftr19Aqnrl+9nr3XMRERF1aBBA0mtZEVRxOHDh+1+Grevry+++OILlClTRlYcq9WK77//Hh9//LHk072Lws3NTdJnsdVqVeVnjKrvxHNzc2XNbLDYoNJEiRFzLy8vFhuPIQiC7P7tAOz+4UtEVFghISGSD/c7depUsR/u9yhNmjTB5MmTJc8W5LNYLPj666+xYMECySd8F5aczxpb5yaFqu/E5U4F6fV63jhRqZGeni47hoeHhwKZlFxKLMuUu9SNiKi4+Pn5oWbNmpKujY+Px6lTpxTOqOgEQUDv3r3Rv39/2QPQOTk5mDp1KrZs2WLTA1rl5KnGg2NVXWzIrc64X4NKEyWmTt3c3BTIpORSYqZUjZv3iIgeRaPR4KmnnpJ0bU5ODg4fPqxwRtI4OztjypQpaNu2rexYKSkpGDt2rE07VEkdKBdFkcVGUcn9UGaxQaWJElOnBoOBs4FERFSgefPmkpcg7d+/XzWzuf7+/pg/fz5q164tO9bly5fxwQcfKLKi4FHk3L9yGVURyS0W1PgXTmQrSvy8s0Ansi8lin01jmyS46pZsyaCgoIkXXvx4kXExcUpnJF01atXx/z58yV/P/fbsWMHlixZYpPXm5xtAGq891V1sSF3M09ubi6XLBARERFJ5Ovri/r160u69vbt27h69aqi+cjVqlUrREZGwsXFRVYcs9mMmTNn4uTJk8okdh+p512JoqjKJiSqLjZcXV1ljfJkZGSw2KBSQ4n9BBwRJbIfQRA4s0Gqo9VqJZ9VkZuba5ObcTk0Gg1ef/11DB8+XPZs/q1btzBlyhTFz9+Q2o1KFEXk5uYqmosSVF1suLu7y3rjTUtLU+V0EpEtsFMSkeNTatCABQcpqWHDhpJnAo4ePapwNvI5OTlh4sSJ6N69u+wC/5dffsG3336r6OC2s7OzpLxEUeQ5G0Ul9wCtxMREVU4nEdkCiw0ix6bRaBTreMZig5RUs2ZNeHt7S7r27NmzxXbydlG4u7vjq6++QkREhKw4eXl5mD59Oo4fP65QZtI7Q1qtVkXO3FKaqouNgIAAWRXnnTt3VHlsO5Et6HQ62THMZjNvUojsSKlig0uISUleXl6oVq2apGtjY2ORnJyscEbKCAoKwtdffy15T0q+27dv44MPPlDs+3R1dZX0mW61WpGamqpIDkpSdbHh7e0NZ2dnydfHxcWpssIjsgWpG8rux+KcyH4EQeAyKlIlg8GAunXrSro2MTERd+/eVTgj5VSrVg3ffPON5JPS8+3duxfz5s1TZIWAk5OTpGVrLDYkcHV1ha+vr+Tr8/LycP36dQUzIlIvqRvK7sdlh0+mxGgxzzGhx1Gq2OAyKlKaRqNBvXr1JC3XtVgsiI2NtUFWymnWrBmmTZsmqwuq1WrF7NmzsW/fPtn56PV6uLq6SrqWezaKyNXVFWXKlJF8vdlsVv0POJFSDAaD7BhqfJNSEyWKDZ5lQo+jZLHBZVSktJo1a0qaQRdFEfHx8TbISDmCIKB79+547bXXZMVJTk7Ghx9+KHsmR6/XSx5AzM7OVt3rX/XFRmBgoOTrWWxQaeLh4SE7xt27dzki+hiiKCInJ0d2HCWWu1HJxGVUpGZlypSRtI9AFEVVLu35t/wOVVWqVJEV5+jRo5g5c6asbqharVbyAGJOTo7qXv+qLjZ0Oh3Kly8v+XpRFHHx4kUuDaFSwcfHR3aMy5cvq25ERE2U2AMmdWqcSj6es0FqZjAYJC8zUmKgpjhUqVIFEyZMkLUs2WKxYPHixfjjjz8kx9DpdJKLjezsbNW9B6i62ACAypUry3rzPXXqFJeGUKng6+sra70pcO+AIrV2DbE3URRx7do12XE8PT0VyIboydR2s0GOTxAEyTMbjtJWXRAE9OjRA127dpV175mamooPPvhA8r5hnU4naxmV2l7/qi82qlWrJmta+erVq6rugkCkFG9vb9k3smlpabh69aoyCZUweXl5iI6Olh0nICBAgWyopGIDASqJ1Hbz+yTOzs74+OOPUb16dVlxTp8+jSlTpiA7O7vI1+p0OslLbrmMSoJKlSpJPtwEuLfh9eTJk8olRKRSAQEBkg9dypeeno5Lly4plFHJEhsbi1u3bsmKodPpWGyQzantRoPI0VStWhVTp06VfGo6cO91+N1332HDhg1Ffk1qNBrJxYbJZFLde4Dqiw0/Pz9UqlRJ8vUmkwlHjx7lOnQq8Xx8fBAUFCQrRl5eHk6fPs3XyyOcOnVK9hIzHx8f+Pv7K5QRlTRsfUukHp06dULfvn1lzTbm5OQgMjKyyM2K5BQbatynrPpiw8vLCzVq1JAV4/Dhw9y3QSWeTqdDzZo1Zcc5ceKEw6yvLS4WiwV79+5Fbm6urDhBQUGy2nlTycbWt0TqodfrMXHiRISFhcmKc+HCBXz55ZdF6k6l0WgkvxdYLBbVDTaovtjQarVo0qSJrMryzJkzspc/EDmC+vXry45x/vx5ZGRkyE+mBElLS5PVWSRflSpVZC91o5JLo9Eocg6L1WrlgAEpTk4x7Kg/j2XKlMFnn30GLy8vyTFEUcSaNWtw6NAh5RJzMKovNgCgadOmkjog5EtPTy/V/8hUetSqVUv2SeKpqamIiYlRKKOS4dChQ5K7itwvPDycG4DpsQRBUKzYUNvIJjk+OT+fjlpsAEBERAQGDRoka9YxOTkZX3zxhaTN4iWBQxQbFStWlHXeRl5eHg4cOCDrgBUiRxASEoLg4GBZMTIzM1ls3MdsNuOnn35CZmamrDgGgwHNmjVTKCsqiZQqNgDHvrkjdZLz86nGfQSFpdfr8e6776Jp06ay4mzfvh3bt29XKCvH4hDFRmBgIOrUqSMrxoEDB5Cenq5QRkTqFBQUJKswB+41VYiJieHI6P/cvn0bv/76q+w4lStXRtWqVRXIiEoqJWe9+PolpckpNhx9D1FgYCCmT58OX19fyTFyc3Mxe/ZsRQ6HdTQOUWzo9Xq0bt1aVozY2FgcPXpUoYyI1MloNMpuqAAAFy9e5Ewg7t2wbd26Fbdv35Ydq1GjRrK7hRER2YucE+4dvdgAgKeffhrvv/++rGX9Bw8exObNm/9zMEDO37UaP7sdotgAgJYtW8rqd5yZmYm1a9c69FQeUWHI7ZwBAOfOneMyDNzb77Vu3TrZ7xsajQYvvviiIp2GiIgcTUmYadNoNBg6dCjat28vOYbJZMJnn332n61wpZ7WDtwrNtT29+0wn3yVKlVCaGiorBi//fYbLl++rFBGROpUo0YN2csxYmNjS+VU77/t27dPkRnR8uXLIzw8XIGMiIjIXjw8PPDxxx/LOpz1/Pnz+Pzzz/9zEMtgMEiKr8ZBdYcpNnx9fdG4cWNZMe7evYt169aViOk8oscJCgqS3V41MzOz1J8knpGRgSVLlijSPaRly5YICQlRICsiIrKnRo0aYcCAAZJnqkVRxOrVq7F169YnPk5OscGZDYkEQUCHDh1kLUOwWq1Ys2YN4uLiFMyMSF18fHxkd6TKyspCdHS0Qhk5pj///FORszV0Oh26d+8ua50vERGpg1arxeDBg2U1/MjMzMSECROeuNpGahv73Nxc1Q2qO0yxAQDNmjVDuXLlZMWIiYnB+vXrVVf1ESnFx8cHZcuWlRXDbDbj77//VuVGs+KQmpqKWbNmISsrS3asWrVqyW6ZSESkBqXxnI1HKVeuHIYOHSprAPzcuXP48MMPH3uIrpxiQ20cqtgICQlB27ZtZcUwm81YvHgxZzeoxDIYDKhevbrsOH/++WepPUl869at2Lt3r+w4giDg5ZdflrW+l4hIDeS2vi1Jg7yCIKBnz56oVauWrDibNm3C0qVLHzkTYTQaJcXMy8tT3UChQxUbGo0Gr7/+OpydnWXFOX/+PNatW1eifvCJ7tegQQPZm8QvX76Mw4cPK5SR47h79y5mz54Nk8kkO5aXlxe6devGU8OJyOEJgiB5JL+kFRsAEBAQgNGjR0veWwHcKwymTZuGffv2PfRnbm5ukmKazWbVnVTuUMUGcG8pVZMmTWTFMJvN+Oabb3Djxg2FsiJSl7CwMMlTsPmysrKwYsUK1b1p2ZLVasWKFStw8uRJReI9++yzqFatmiKxiIjsSc7MhtpG2pXSvXt3REREyIoRHx+P995776H9G+7u7pLiWa1W1X1uO1yx4ebmhr59+8ruV3/hwgXMmDFDlS3CiOQqU6YMKleuLDvOtm3bFNkk7SjOnDmDBQsWKLK+2Gg0on///pKnwomI1ETuoX4lbWYDuHdPOnnyZNlLZU+cOIGhQ4fi7t27Bb8ndRWP1WpV3b2twxUbAPDCCy/IPiU5fwTzhx9+KJEvACrd/Pz8UK9ePdlxMjIy8Mknn5SKWcDs7GzMmDED165dUyTe008/zbM1iKhEkdPutaRq3LgxRowYIXnWJ9/27dsxatQopKamAoDkg6wtFgtycnJk5aI0hyw2goKC8MYbb8heB52RkYFx48Zhz549yiRGpBI6nQ7t27dX5MTq48eP49133y3xTRV++uknbNiwQZFYRqMRQ4cOhYeHhyLxiIhInbRaLYYMGYJWrVrJiiOKIn744QdMmTIFOTk5cHV1lRTHarWy2FBKr169FFkmcv36dbz55pv45ZdfVNeXmEiO1q1bK9IFSRRFbNy4EYMHDy6xMxxXrlzB1KlTFVvn2qZNG9nreImIyDH4+vpi2rRpCAwMlBXHYrFg4cKFmD17tuTZIFEUVXc/67DFRoUKFdCvXz9FurxcvXoV/fr1w9dff626TTVEUoWEhCh2w2u1WrF582b06dMHUVFRisRUi5ycHEydOlWxQwzd3d0xevRoyZv7iIjI8TRr1gwTJkyQ1Z0KuLekd+rUqViyZInkGGpbtuawxQYA9O7dG1WqVFEkVnx8PMaOHYsRI0aU2NFbKl2cnJzQq1cvxTYoi6KI3bt3o2fPnti1a5fq3sykEEURq1atwtq1axWJJwgCXnrpJdnT6URE5FgEQcCAAQPw6quvyh4Iz8rKkrzEnxvEFVa+fHkMGDBAkXXpwL0RzuXLl6Nz587Ys2eP6qahiIrqqaeeQvPmzRWNGRUVhTfeeAMrV65U5CwKe9qzZw8+/vhjxWY0/f398e6777IDFRFRKeTi4oLIyEjUrVvXbjmIoqi6E9sdutgQBAF9+/ZV9B/VarXi2LFjeO211zB79uxSe4Lyv1mt1oIvi8UCs9msuh9mepinpyeGDBmi+M3v7du3MWzYMHz00UdITk5WNHZx+eeffzBixAjcvn1bkXgajQZ9+/ZFgwYNFIlHRESOp1KlSpgxYwZ8fHzs8vxarVZ1A146eycgV3BwMMaNG4cBAwYgKytLsbhxcXEYP348jh07hmnTpqFixYqKxVYbk8mE5ORkXLx4EdevX0dKSgpyc3Oh09378UhPT0dqamrBKHZmZiYyMzPh7u6OunXron379qhcubLstm9kGy+88AIiIiKwbds2ReNmZWVh5syZOHPmTMFIjqOclH38+HEMGjRIsX0aAFCtWjUMHz6crwOSTM6haf/GwSAi+2nXrh0mTJiA8ePHF/sKAJ1Op7pOiA5fbABA586dsX37dqxYsULRdeQmkwlr167F2bNnMXPmTLRu3bpE3Ujk5ORgz549WL58OQ4ePIjU1FTk5ubCbDbDarUW3Dg+6e9Uq9UiMDAQAwcOxMiRI+Ht7V1c6VMhubm5Ydy4cTh8+DASExMVjW2xWPDzzz8jKioK7733Ht544w14eXkp+hxKysvLw6+//ooxY8bgwoULisU1Go14//33Ua5cOcViUukj59C0fyupJzYTOQKtVouhQ4ciNjYWCxYsKNbXo8FgUN3nsEMvo8rn5OSEjz76SJFDzP5NFEWcPHkSPXr0wLx580rMsqrr169jyJAh6NatG9avX48bN24gPT0dJpOpYK+KKIr/WbxZLBbcunULkZGRGDJkCJKSkoojfSqiZs2aYdCgQQWzVUq7evUq3n33XXTt2hU7duxQZVe3xMREREZGom/fvooWGgDw7LPP4rXXXnOYmR1SL6Veo2rbIEpU2hiNRkydOhU9evRQbG9xYVSoUMFuS7gep0QUG8D/XyPn7+9vk/jx8fH44IMPMHjwYMTExDh0J54rV66gd+/eWLlypWLFk9lsxoYNG/DFF19wRE2F9Ho9Ro0ahaeeespmz5GXl4edO3eiS5cuGDBgAA4ePIjc3FybPV9h5ebmYvfu3ejatSsiIyORkpKiaPwyZcpg0qRJcHNzUzQulT5arVax2XMWG0T25+HhgS+//BLt2rUrlufTaDTo2LEjnJ2di+X5CqvEFBsAEBERgSlTptjsQ99kMmHNmjXo1KkTNm3apLoTGgsjPT0dY8aMwb59+xQvmCwWC5YuXYqzZ88qGpeUERAQgBkzZth8/1FGRga+//57vPTSSxg0aBD27t2r6H6qwrJYLIiKisI777yDLl26YM+ePYoXwjqdDiNHjuSmcFKERqOBXq9XJJYaCn0iAgIDAzFv3jzUr1/f5s9VrVo19O7dW3Wz7CWq2NBqtRgwYADGjh1rs6pOFEVER0ejb9++GDlyJC5duuQwsxxmsxmLFi3C1q1bbZZzYmIifv75Z5vEJvmaNGmCWbNm2WwG8H7JyclYtWoVOnbsiJdffhmLFy/GtWvXbD7zZbFYcO7cOUyYMAEdOnTAkiVLFJ/NyNe2bVsMGjSoWKfIqeTSaDSKLaNSS1vq7Oxs3L59GzExMbh48SJiY2ORkpLiMJ+bREqoVq0avv32W9SoUcNmzxEYGIivvvoKFSpUsNlzSFUiNojfz2AwYMyYMcjLy8PMmTNtNqKamZmJJUuWYNeuXRg2bBh69uyJgIAA1VWT+axWKzZt2oRp06bZ9ENIFEVcvnzZZvFJHkEQ0LFjR8yePRvvvPOO4hvGHyU9PR07d+7Evn37EBQUhHbt2uGll15CixYt4O/vr8iyEVEUkZmZiUOHDmH9+vX45ZdfcOfOHZuelRMSEoLIyEjVbcQjx6VksWGvZVS5ubnIyMhAdHQ0Dhw4gKNHj+LMmTO4ffs2zGYzPD09ERoairZt26Jnz56oUqVKiWq8QvQ4DRo0wIoVK9C3b1+cP39esbg6nQ7169fH559/jmeeeUaxuEoqccUGcG9TzoQJE+Dh4WGTNdr5RFHEpUuXMGbMGCxbtgx9+vRBly5dEBISAicnJ5s8pxQWiwWbN2/GyJEji+VMBI5YqZtWq8Vrr70GjUaDkSNHIi4urlieNy8vD9evX8fy5cvx/fffIygoCE2aNEGrVq1Qp04dVKxYEcHBwTAYDADwxMI9v3lBWloaoqKisGvXLmzduhXnz59Henq6zb8Xo9GIiRMnolGjRjZ/Lip++T9f9zfJyP9vXl4ecnJyYDKZYDabC84cyj+HSBAEaDQaaDSagv/P7zJ1/5/l78/QarUFvzaZTIoeUltc++cyMzNx+vRpnDhxAocPH8ahQ4dw9+5dmEymh1rwZmVl4fbt29i/fz+WLVuG999/H2+99RZcXFyKJVcie2rWrBm+/fZb9O/fX3ajknLlyqFZs2Z47rnn0LFjRwQEBCiUpfIEsQTfGZrNZvzwww/44IMPcP36dZs/n0ajQUBAAJo3b47mzZujdu3aqFy5Mjw8PGA0GmE0GmEwGKDVap/Y4vC/Zkdyc3ORnZ2N3Nxc5OXlFXzY5X8IpqWlITExETdv3sSdO3cQGxuLbdu2Fdvha2+99RaWLFlSLM9F0lmtVmzbtg0jRoxAbGys3fIQBAFubm7w8vKCj48PKleujIoVK8Lf3x/u7u5wdnaGIAjIzc1FVlYWMjMzkZSUhCtXruDChQu4ffs2UlNTizXfwYMH46uvvlLdwUkkj8lkwsmTJ3H48GFERUUhPj4eqampBT932dnZBR37RFEs+O/9BUn++/f97+P//v/7H3P/r0VRRHx8vCL7LWrUqFEsyyksFguuXLmCxMREpKenF/l8DycnJwwZMgRTp05lkwWVS0lJQUREBE6cOFHka/v06YNvv/2Ws1j/s3//fvTu3RtXr16VdH3VqlWxYcMG1K5d22ZdJpVUoosN4N6b919//YV3330Xhw8ftumyivvlj2Dp9Xr4+PjAx8cHfn5+cHd3h5OT0xMLjvtHuvR6/QMjXdnZ2UhMTERcXBySkpIe+ADMnzb/96hccf4TazQafPbZZxg7dmyxPSdJJ4oiDhw4gOHDh+Off/6xdzoO4bnnnsOKFSsQGBho71RIIRaLBX/99RdmzJiB/fv3IzExkTO0xcjJyQkTJ07E+PHjeTOqYsnJyWjTpg1OnTpV5Gv79u2LZcuW8d/3Prt27cIbb7yB27dvF+k6d3d3LF++HK+++qqNMrMBsZS4efOmOGjQINHZ2VkEwC8bfQUFBYnR0dH2/uemIjp79qzYoUMHUaPR2P1nSM1fjRo1Es+fP2/vfy5SkMlkEpcuXSoGBgba/eerNH8FBgaKBw8etPePAz3BtWvXRH9/f0n/vgMHDhStVqu9vwVVsVqt4vr160Vvb+9C/z0ajUZx+vTposlksnf6RVJqWqiUKVMGc+bMwZw5c1C2bFl7p1Mi6XQ6DBkyBNWrV7d3KlRENWrUwKpVqzBw4EAuDXqM2rVrY/HixahWrZq9UyGFiKKItWvX4r333sPdu3ftnU6pdvfuXXz77bc8H0TFEhMTJZ/N5eHhodoGOvYiCAK6dOmCyMhIuLu7/+fj9Xo9hg8fjnfeeUexFtnFpdQUG8C9TZ1vvfUWNm3ahJYtW7JdpYL0ej169+6NUaNGcZrUQQUEBGDWrFn47LPP4OfnZ+90VKVevXpYvnw5GjZsaO9USEHR0dGYNGlSse75ocf77bffim1vIRVdamqqpKXogiAUS7t1R6TVavHWW29hzpw5KFeu3GMf5+3tjQkTJmDy5MmqO7CvMNS/q0RhgiCgadOm2LBhA6ZMmYIVK1YgOzvb3mk5LI1Gg0qVKmHw4MEYPHgwN/g5OGdnZ4wYMQI1atTAmDFjEB0dXarXrguCgBYtWuCbb75B3bp17Z0OKSgvLw9ff/21XZsj0INSUlJw5swZVXfVKc1yc3MlfR4IgsAW4U+g1+vRr18/PPXUU1i9ejV2796NmzdvwmKxIDAwEM2bN0fv3r3RqFEjhx3MLXXFRr7AwEDMmjULDRs2xOTJk3Hr1i17p+QwjEYjypcvj0aNGuGFF15Aq1atUK5cOU6RlhBarRbPPfccqlatikmTJmHz5s2lsiA3GAzo0qULPv/8c5QvX97e6ZDCbt26hS1btpTqYlpt8vLyirxZloqP1AY7giDA09NT4WxKFkEQUK1aNUydOhUZGRnIyMiAKIpwcXEpEUvQSm2xAdzrgDFgwADUqVMHo0ePxpEjR/jB8wgeHh4ICQlBtWrV0Lx5c4SHh6N69eqqPsSQ5KtatSqWLl2KiIgITJ8+HTExMaXm9eHj44NRo0Zh1KhRhVpLS47nr7/+4pIdoiKQem4LZzaKxs3NrcStEinVxQZw70XQvHlzbNq0CVOnTsXKlSttduq4o/Hx8cHkyZPRqlUrhISEwNfXl8VFKePi4oI333wTrVu3xsyZM7F27VqbHZKpBhqNBvXq1UNkZCSeffZZh+hfTtLExMTAZDLZOw26j16vR3BwsL3ToMfIP/NICjYeKd24Q/p/goODMXv2bCxZsoTdZgC4urpi6tSpGDZsGOrXrw8/Pz8WGqWUIAioWrUq5syZgw0bNqBDhw4l8oPD09MTQ4cOxU8//YQXXniBhUYJl5WVVWpm6hyFl5cXatasae806DHKlCkDg8FQ5OuMRiOCgoJskBE5ChYb9zEYDOjVqxe2bduGfv36OeSOfyW4uLhg8uTJeOuttxx2MxIpz2AwICIiAj/88AOWLVuG5s2bO1z7vUfR6/Vo06YN1q5di5kzZz6xIwiVHJ6enuxIqDLPP/88fHx87J0GPUaZMmUkFYO1a9dGmTJlbJAROQq+0z5C1apV8c0332DlypWoX79+qfpA8vT0xPTp0zFy5EhJIxhU8rm7u6NXr174+eefsXjxYoctOjQaDWrXro158+Zh06ZNeO655/gzX4pUr14dTk5O9k6D/icoKAgDBgxwyPeS0sLT0xO9e/cu0iCkVqtFnz594OHhYcPMSO0EkfPIT3Tnzh0sXboUy5YtQ2xsbImedg8JCcGMGTPQrVs3LiGhQktKSsKePXuwatUq7N27F6mpqap+nWg0GlStWhVvvvkmXn/9dZQtW5ZLBEuhuLg4tGjRAjExMfZOpdRzcnLC5MmTMW7cOL4WVS41NRU9e/bEr7/+WqjHv/jii1izZg2LjVKOxUYhiKKIy5cvY8WKFVizZg2uXr0quQWcGmk0GjRv3hxffPEFwsPD+WZPkmRlZeH8+fPYtGkTfvnlF5w+fVpVpwHr9Xo0aNAAr7/+Ojp37oyQkBD+rJdiFosFU6ZMQWRkZIl6P3c0Tk5OGDp0KD755JMS14GnpIqNjcXgwYOxY8cOWCyWRz5Gp9OhXbt2WLhwISpUqFDMGZLasNgoAqvVihs3bmDz5s34/vvvcfLkScmH3KiBRqNBYGAg3nrrLQwbNgyBgYH2TolKiPj4ePz999/YuHEj9u3bh5iYGLsUHoIgoEyZMmjVqhV69eqF8PBw+Pr6FnsepE7Xr1/Hyy+/jJMnT9o7lVJHEASUK1cOY8aMQb9+/VhoOJjExEQsWbIEK1euxPXr15GTkwPg3mbwcuXKoV+/fnjrrbf4fksAWGxIlpKSglOnTmHr1q3Yv38/oqOjkZ2dDYvForriQxAECIIAjUYDjUYDPz8/1KxZExEREejcuTNCQ0O5EZxsQhRF3LlzB6dPn8b27dtx4MABXL58GQkJCTYbTdZoNAgODkb9+vXxyiuvoHXr1qhUqRKXBtIj7dq1C2+++SZPEi8GgiAgKCgI1atXR0REBF577TVUrlyZnz8Oymq1IikpCVFRUbhx4waAe8ux69atC29v71K135WejMWGTKIoIi0treCGKioqCpcuXcLNmzdx584dxMXFISsrC1arFaIoFnz9V8zH/Tq/cBAEAVqtFjqdDq6urjAajTAYDDAajTAajXB1dYWnpyd8fX0REBCAoKAglC1bFpUqVUJQUBC8vLw4kkTFLiMjA1evXkVMTAyOHz+Of/75B9euXUNSUhJSUlKQkZFRpCJEo9HAzc0N3t7eCAoKQsOGDfHMM88gLCwMlSpV4mZT+k+iKGLXrl14//33cerUKS6pUpBOp4Ofnx/Kly+PZs2aoXXr1qhZsyZCQkK4hp+oFGGxYQNmsxk5OTkFXykpKYiPj0dycjIyMzORm5sLi8XyyA+1/JkRs9kMs9n80ON0Oh3c3Nzg5+eHkJAQBAcHw8nJCVqttmDmIr8I0el0MBgMHF0gVUtPT0dcXBzi4+ORkJCA+Ph4JCYmIjU1FZmZmTCbzRBFEXq9HkajES4uLnB3d4e3tzf8/Pzg6+sLf39/lClTpkSe/0HFIzY2FsuWLcP333+PO3fuFAwSUeHodDo4OTnB1dUVISEhaNGiBVq0aIHatWsjNDS01LaSJyIWG0RERADuLQtJTEzE0aNHcenSJaSmpj5UcIiiiOzsbKSlpSElJaWgQE5KSkJaWlrBgNH9s9iP+v/H/V5hCIIAvV4PT09PPPvss6hbt65dmx1otVq4u7sjODgY1atXR4UKFaDX6znQRUQAWGwQERE90uM+Hq1WK6xWKywWC8xm8wP/n5mZiezsbJhMJuTm5sJkMsFkMiEnJwe5ubkFM965ubnIzs5GTk5OwX9zc3ORl5f3xKJDEAR4eXmhbt26aN68OcqUKcPzQohI1VhsEBERERGRTXCOk4iIiIiIbILFBhERERER2QSLDSIiIiIisgkWG0REREREZBMsNoiIiIiIyCZYbBARERERkU2w2CAiIiIiIptgsUFERERERDbBYoOIiIiIiGyCxQYREREREdkEiw0iIiIiIrIJFhtERERERGQTLDaIiIiIiMgmWGwQEREREZFNsNggIiIiIiKbYLFBREREREQ2wWKDiIiIiIhsgsUGERERERHZBIsNIiIiIiKyCRYbRERERERkEyw2iIiIiIjIJlhsEBERERGRTbDYICIiIiIim2CxQURERERENsFig4iIiIiIbILFBhERERER2QSLDSIiIiIisgkWG0REREREZBMsNoiIiIiIyCZYbBARERERkU2w2CAiIiIiIptgsUFERERERDbBYoOIiIiIiGyCxQYREREREdkEiw0iIiIiIrIJFhtERERERGQTLDaIiIiIiMgmWGwQEREREZFNsNggIiIiIiKbYLFBREREREQ2wWKDiIiIiIhsgsUGERERERHZxP8DB56+3W/qge0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def crop_pillow_image(image, bounding_boxes, padding=60):\n",
    "    \"\"\"\n",
    "    Crop a Pillow image based on the given list of bounding box coordinates and pad with white pixels.\n",
    "\n",
    "    Args:\n",
    "    - image: Pillow image object\n",
    "    - bounding_boxes: List of bounding box coordinates (each bounding box is a tuple (x, y, w, h))\n",
    "    - padding: Amount of padding to add around the bounding box (default: 10 pixels)\n",
    "\n",
    "    Returns:\n",
    "    - cropped_images: List of cropped and padded Pillow image objects\n",
    "    \"\"\"\n",
    "    cropped_images = []\n",
    "    for bbox in bounding_boxes:\n",
    "        x, y, w, h = bbox\n",
    "        # Crop the image using the provided coordinates\n",
    "        cropped_image = image.crop((x, y, x + w, y + h))\n",
    "        # Create a larger canvas with white background\n",
    "        padded_image = Image.new('L', (w + 2 * padding, h + 2 * padding), color=255)\n",
    "        # Paste the cropped image onto the canvas with an offset\n",
    "        padded_image.paste(cropped_image, (padding, padding))\n",
    "        # padded_image.show()\n",
    "        cropped_images.append(padded_image)\n",
    "    return cropped_images\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \n",
    "    orig_img = Image.open(image_path)\n",
    "    \n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Apply thresholding to get binary image\n",
    "    _, img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    # Invert the image\n",
    "    img = cv2.bitwise_not(img)\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Extract bounding boxes of contours\n",
    "    bounding_boxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "    # Sort bounding boxes by x-coordinate to get characters from left to right\n",
    "    bounding_boxes.sort(key=lambda x: x[0])\n",
    "    # Extract individual characters\n",
    "    characters = []\n",
    "    # for x, y, w, h in bounding_boxes:\n",
    "    #     character = img[y:y+h, x:x+w]\n",
    "    #     characters.append(Image.fromarray(character)\n",
    "\n",
    "    return crop_pillow_image(orig_img, bounding_boxes)\n",
    "\n",
    "def infer_characters(characters):\n",
    "    '''\n",
    "    Returns test accuracy\n",
    "    \n",
    "        Parameters:\n",
    "            net (CNN): a trained model\n",
    "            args (ArgumentParser): hyperparameters\n",
    "        \n",
    "        Returns:\n",
    "            test_acc (float): test accuracy of a trained model\n",
    "    '''\n",
    "\n",
    "    model.load_state_dict(torch.load('model.pt'))\n",
    "    model.eval()\n",
    "\n",
    "    def predict_image(image, model):\n",
    "        # Define transforms for the dataset\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((32, 32)),    # Resize images to (32, 32)\n",
    "            transforms.Grayscale(),         # Convert images to grayscale\n",
    "            # ToBinary(threshold=128),        # Convert images to binary using thresholding\n",
    "            transforms.ToTensor()           # Convert images to PyTorch tensors\n",
    "        ])\n",
    "        image = transform(image)\n",
    "        image = torch.unsqueeze(image, 0)  # Add batch dimension\n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            return predicted.item()\n",
    "    \n",
    "    predicted_chars = []\n",
    "    # Iterate through each image in the folder\n",
    "    for character in characters:\n",
    "        predicted_label = predict_image(character, model)\n",
    "        predicted_char = emnist_byclass_label_to_char(predicted_label)\n",
    "        predicted_chars.append(predicted_char)\n",
    "    \n",
    "    return predicted_chars\n",
    "\n",
    "\n",
    "def recognize_text(image_path):\n",
    "\n",
    "    # Preprocess the image\n",
    "    characters = preprocess_image(image_path)\n",
    "    # Convert the predictions to text\n",
    "    predicted_chars = infer_characters(characters)\n",
    "    return ''.join(predicted_chars), characters\n",
    "\n",
    "# Provide the path to your input image\n",
    "input_image_path = 'test_imgs/Words/COIN.png'\n",
    "# Recognize the text in the image\n",
    "recognized_text, original_characters = recognize_text(input_image_path)\n",
    "\n",
    "print(\"Recognized Text:\", recognized_text)\n",
    "\n",
    "# Plot the characters for visual inspection\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, character in enumerate(original_characters, 1):\n",
    "    plt.subplot(1, len(original_characters), i)\n",
    "    plt.imshow(character, cmap='gray')\n",
    "    plt.title('Character {}'.format(i))\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
